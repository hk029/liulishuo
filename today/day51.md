# day51 How people think that self-driving cars should behave in an accident?
自动驾驶汽车在事故中应该保护谁？
## 原文

In a paper just published in Nature, a team of psychologists and computer scientists describe a different approach. They created the “Moral Machine”, a website which presents visitors with a series of choices about whom to save and whom to kill.
> 在最近发表于《自然》杂志上的一篇论文中，一支由心理学家和计算机科学家组成的团队描述了另一种方法。他们创造了“道德机器”网站。这个网站会给访客展示一系列的选择，从而决定该救谁，该杀谁。


The strongest **preferences**, expressed by respondents from all over the world, were for saving human lives over animal ones, preferring to save many rather than few and prioritising children over the old. There were weaker **preferences** for saving women over men, **pedestrians** over passengers in the car and for taking action rather than doing nothing. Criminals were seen as **literally** **subhuman**—ranking below dogs in the public’s priority list, but above cats. It is easy to imagine the **utilitarian** argument for preserving the lives of doctors over others. Humanity’s (weak) **preference** for saving athletes seems less **intuitive**.
> 全世界的答卷人展现出的最明显的倾向是，优先救人类而不是动物的性命，优先救多数而不是少数，优先救孩子而不是老人。以下几种倾向则没有那么明显：救女性而非男性，行人而非车里的乘客，采取行动而非听其自然。罪犯真正意义上地被视为低人一等，在公众的优先级名单上排序低于狗，但是高于猫。优先救医生而非其他人的性命，这背后功利主义的考量并不难想象。但人们（较弱的）优先救运动员的倾向，看起来就没那么容易理解了。


Many people, says Dr Rahwan, a computer scientist at MIT and one of **the** paper’s authors, **dismiss** **the** **trolley** **problem** as a piece of pointless hypothesising that is **vanishingly** unlikely to arise in real life. He is unconvinced. The specific situations posed by the website may hardly ever occur, he says. But all sorts of choices made by the firms producing self-driving cars will affect who lives and who dies in indirect, statistical ways. He gives the example of overtaking cyclists: “If you stay relatively near to the cycle lane, you’re increasing the chance of hitting a cyclist, but reducing the chance of hitting another car in the next lane over,” he says. “Repeat that over hundreds of millions of trips, and you’re going to see a **skew** in the [accident] statistics.”
> 拉万博士是麻省理工的计算机科学家，也是这篇论文的作者之一，他说许多人不再思考电车问题，将它视为一个没有意义的假说，认为它几乎不可能在现实中出现。拉万并没有被这种看法说服。他说，网站上给出的具体场景可能几乎不会出现，但是生产自动驾驶汽车的公司做的各种各样的抉择会影响到孰生孰死，这种影响是间接的，统计学层面的。他拿赶超骑行者一事举了例子：“如果你相对离自行车道近一些，你就增加了撞到骑行者的几率，但是降低了和旁边车道的另一辆汽车相撞的几率。”他说，“在上亿次旅行中重复这一情况，你就发现事故统计数据的偏态。”

----
## quick scan


在最近发表于《自然》杂志上的一篇论文中，一支团队创造了“道德<u>Moral</u>机器”网站。这个网站会给访客展示一系列的选择，从而决定该救谁，该杀谁。

全世界的答卷人展现出的最明显的倾向preferences是，<u>perfer to</u>优先救人类而不是<u>rather than</u>动物的性命，优先救多数而不是少数，<u>prioritise</u>优先救孩子而不是<u>over</u>老人。以下几种倾向则没有那么明显：<u>preferences for</u>救女性而非<u>over</u>男性，行人<u>pedestrians</u>而非车里的乘客，采取行动而非听其自然。罪犯真正意义上地被视为低人一等subhuman，在公众的优先级名单上排序低于狗，但是高于猫。优先救医生而非其他人的性命，这背后功利主义<u>utilitarian</u>的考量并不难想象。但人们（较弱的）优先救运动员的倾向，看起来就没那么容易理解<u>intuitive</u>了。

拉万博士是麻省理工的计算机科学家，也是这篇论文的作者之一，他说许多人不再思考<u>dismiss</u>电车问题<u>the trolley problem</u>，将它视为一个没有意义的<u>vanishingly</u>假说<u>hypothesising</u>，认为它几乎不可能在现实中出现。拉万并没有被这种看法说服。他说，网站上给出的具体场景可能几乎不会出现，但是生产自动驾驶汽车的公司做的各种各样的<u>all sorts of</u> 抉择会影响到孰生孰死，这种影响是间接的，统计学层面的。他拿赶超骑行者一事举了例子：“如果你相对离自行车道近一些，你就增加了撞到骑行者的几率，但是降低了和旁边车道的另一辆汽车相撞的几率。”他说，“在上亿次旅行中重复这一情况，你就发现事故统计数据的偏态<u>skew</u>。”

----
## word
### moral
* adj. 道德的
    * . a moral judgement
* n. 道德
    * . moral codes
### preference
* n. 偏爱；偏爱的事物；优先选择权
    * . a preference for seafood over steak
    * . choose to eat seafood in preference to steak
### pedestrian
* n. 步行者，行人
### literally
* adv. 字面意义地；（夸张）简直
    * . His brain was literally turned off.
    * . I have made literally thousands of phone calls.
### subhuman
* adj. 不齿于人类的；低于人类的
    * . Parents regard all game junkies as subhuman.
### utilitarian
* adj. 功利主义的
### intuitive
* adj. 容易理解的
### dismiss
* v. 把…打发走；不再考虑
### hypothesise
* v. 假设，假定
### vanishingly
* adv. 可以忽略地
### skew
* n. （统计）偏态，偏斜性
## phrases
### the trolley problem
* 电车问题
## extend
### 优先考虑
* prefer to ... rather than ...
    * 宁愿做某事而不做另一件事
        * . prefer to sleep rather than swim
* prioritise ... over ...
    * 优先考虑 A 而不是 B
* preference of ... over
    * 优先考虑 A 而不是 B

*XMind: ZEN - Trial Version*